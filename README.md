def ask_ollama(user_message):
# Local AI Coding Platform

A professional, privacy-first local AI platform for experimentation, education, and advanced integrations. Supports FastAPI, Ollama, LangChain RAG, ChatGPT Actions, Claude Desktop MCP, and more.

---

## ğŸ“ Project Structure

```
AI-Coding/
â”œâ”€â”€ ai_core/            # Core AI application code
â”‚   â”œâ”€â”€ educational_ai_example.py  # Educational tutorial with detailed comments
â”‚   â”œâ”€â”€ simple_ai_client.py        # Production-ready minimal AI client
â”‚   â”œâ”€â”€ ai_web_service.py          # FastAPI web service
â”‚   â””â”€â”€ api_client_example.py      # API client usage example
â”œâ”€â”€ docs/               # Project documentation
â”‚   â”œâ”€â”€ API_Documentation.md # Complete API reference
â”‚   â”œâ”€â”€ PROGRAM_GUIDE.md     # Program usage guide
â”‚   â”œâ”€â”€ DIRECTORY_STRUCTURE.md # Directory structure reference
â”‚   â”œâ”€â”€ GIT_WORKFLOW.md      # Git usage guide
â”‚   â”œâ”€â”€ GLOSSARY.md          # Technology glossary
â”‚   â””â”€â”€ ...                  # Other documentation
â”œâ”€â”€ tests/              # Testing and validation scripts
â”‚   â”œâ”€â”€ test_ai_connection.py      # AI connectivity tests
â”‚   â”œâ”€â”€ comprehensive_test.py      # Full system validation
â”‚   â””â”€â”€ check_documentation.py    # Documentation verification
â”œâ”€â”€ config/             # Configuration files
â”‚   â”œâ”€â”€ requirements.txt # Python dependencies
â”‚   â””â”€â”€ .env            # Environment variables
â”œâ”€â”€ MCP/                # Claude Desktop MCP integration
â”‚   â”œâ”€â”€ file_server.py  # MCP server for Claude Desktop
â”‚   â”œâ”€â”€ secret_data.txt # Test data file
â”‚   â””â”€â”€ *.json          # MCP configuration files
â”œâ”€â”€ chatGpt_MCP/        # ChatGPT integration alternatives
â”‚   â”œâ”€â”€ chatgpt_file_api.py         # REST API for file access
â”‚   â”œâ”€â”€ chatgpt_upload_interface.py # Web upload interface
â”‚   â”œâ”€â”€ chatgpt_demo.py             # Interactive demo
â”‚   â”œâ”€â”€ test_chatgpt_integration.py # Test suite
â”‚   â””â”€â”€ CHATGPT_INTEGRATION_GUIDE.md # Complete guide
â”œâ”€â”€ chatgpt_actions/    # ChatGPT Actions API & guides
â”‚   â”œâ”€â”€ actions_api_server.py       # FastAPI server for Actions
â”‚   â”œâ”€â”€ openapi.json               # OpenAPI schema for Actions
â”‚   â”œâ”€â”€ ACTIONS_SETUP_GUIDE.md     # Setup guide for Actions
â”‚   â”œâ”€â”€ NGROK_SETUP.md             # ngrok setup guide
â”‚   â””â”€â”€ ...                        # Other integration docs
â”œâ”€â”€ LangChain/          # Local RAG (LangChain + Ollama + Streamlit)
â”‚   â”œâ”€â”€ rag_app.py                # Streamlit RAG app
â”‚   â”œâ”€â”€ requirements.txt          # Dependencies for RAG app
â”‚   â”œâ”€â”€ README.md                 # RAG app usage guide
â”‚   â””â”€â”€ USAGE_GUIDE.md            # Step-by-step usage instructions
â”œâ”€â”€ Alert_llm/          # Alert simulation & LLM troubleshooting
â”‚   â”œâ”€â”€ alert_simulator.py        # Sends simulated alerts
â”‚   â”œâ”€â”€ webhook_receiver.py       # Receives alerts, queries LLM
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â””â”€â”€ README.md                 # Project documentation & sample output
â”œâ”€â”€ .AIvenv/            # Python virtual environment
â””â”€â”€ README.md           # This documentation
```

---

## ï¿½ Features
- Local AI processing (no API keys required)
- FastAPI web API and Python script interfaces
- Privacy-first: all data stays on your machine
- LangChain RAG demo (upload your own docs, ask questions)
- ChatGPT Actions and Claude Desktop MCP integrations
- Easy onboarding, professional documentation, and troubleshooting guides

---

## ğŸ› ï¸ Quickstart

1. **Clone the repository**
2. **Create a virtual environment**
  ```bash
  python -m venv .AIvenv
  source .AIvenv/bin/activate
  ```
3. **Install dependencies**
  ```bash
  pip install -r config/requirements.txt
  pip install -r LangChain/requirements.txt  # For RAG app
  ```
4. **Start Ollama**
  ```bash
  ollama serve
  ollama pull llama3
  ```
5. **Run FastAPI server**
  ```bash
  cd ai_core && python ai_web_service.py
  # or
  python -m uvicorn ai_core.ai_web_service:app --reload --port 8000
  ```
6. **Try the RAG app**
  ```bash
  streamlit run LangChain/rag_app.py
  ```

---

## ï¿½ Documentation
- See `docs/` for API reference, guides, and troubleshooting
- See `LangChain/README.md` for RAG app usage
- See `chatgpt_actions/ACTIONS_SETUP_GUIDE.md` for ChatGPT Actions
- See `MCP/` for Claude Desktop integration

---

## ğŸ“¦ Project Highlights

### Alert_llm: Automated Alert Simulation & LLM Troubleshooting

A self-contained Python mini-project for simulating alerts and receiving automated troubleshooting/RCA suggestions from a local Ollama LLM.

- **Location:** `Alert_llm/`
- **Features:**
  - Simulates realistic alerts and sends them to a webhook
  - Receives alerts, prints them, and queries a local LLM for troubleshooting/root cause analysis
  - Includes a sample output in its own README
- **How to use:**
  - See [`Alert_llm/README.md`](./Alert_llm/README.md) for setup, usage, and sample output

---

## ğŸ¤ Contributing
- Fork, branch, and submit PRs
- See `docs/GIT_WORKFLOW.md` for workflow
- All contributions welcome!

---

## ğŸ“ License
MIT License

---

**Happy AI building!** ğŸš€ğŸ¤–